{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d0ec3bc",
   "metadata": {},
   "source": [
    "# 1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c9efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Necessary Libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from sklearn import metrics\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "from matplotlib.pylab import rcParams\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe46f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read files:\n",
    "train = pd.read_csv(r\"C:\\Users\\Manu\\Documents\\ineuron\\Internship\\Store_Sales_Prediction\\data_given\\Train.csv\")\n",
    "test = pd.read_csv(r\"C:\\Users\\Manu\\Documents\\ineuron\\Internship\\Store_Sales_Prediction\\data_given\\Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b143538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918c75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e69dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 13) (5681, 12) (14204, 13)\n"
     ]
    }
   ],
   "source": [
    "#Combine test and train into one file\n",
    "train['source']='train'\n",
    "test['source']='test'\n",
    "data = pd.concat([train, test],ignore_index=True)\n",
    "print (train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39e9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting column names to lowercase\n",
    "data= data.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c119a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check missing values:\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ab7f76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profile = ProfileReport(data)\n",
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462d7fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Number of unique values in each:\n",
    "data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5da3bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency of Categories for varible item_fat_content\n",
      "Low Fat    8485\n",
      "Regular    4824\n",
      "LF          522\n",
      "reg         195\n",
      "low fat     178\n",
      "Name: item_fat_content, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible item_type\n",
      "Fruits and Vegetables    2013\n",
      "Snack Foods              1989\n",
      "Household                1548\n",
      "Frozen Foods             1426\n",
      "Dairy                    1136\n",
      "Baking Goods             1086\n",
      "Canned                   1084\n",
      "Health and Hygiene        858\n",
      "Meat                      736\n",
      "Soft Drinks               726\n",
      "Breads                    416\n",
      "Hard Drinks               362\n",
      "Others                    280\n",
      "Starchy Foods             269\n",
      "Breakfast                 186\n",
      "Seafood                    89\n",
      "Name: item_type, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible outlet_size\n",
      "Medium    4655\n",
      "Small     3980\n",
      "High      1553\n",
      "Name: outlet_size, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible outlet_location_type\n",
      "Tier 3    5583\n",
      "Tier 2    4641\n",
      "Tier 1    3980\n",
      "Name: outlet_location_type, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible outlet_type\n",
      "Supermarket Type1    9294\n",
      "Grocery Store        1805\n",
      "Supermarket Type3    1559\n",
      "Supermarket Type2    1546\n",
      "Name: outlet_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Filter categorical variables\n",
    "categorical_columns = [x for x in data.dtypes.index if data.dtypes[x]=='object']\n",
    "#Exclude ID cols and source:\n",
    "categorical_columns = [x for x in categorical_columns if x not in ['item_identifier','outlet_identifier','source']]\n",
    "#Print frequency of categories\n",
    "for col in categorical_columns:\n",
    "    print ('\\nFrequency of Categories for varible %s'%col)\n",
    "    print (data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db7f4f",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f5639",
   "metadata": {},
   "source": [
    "### Modify Item_Visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32309551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0 values initially: 879\n"
     ]
    }
   ],
   "source": [
    "#Checking number of 0s in Item_Visibility\n",
    "miss_bool = (data['item_visibility'] == 0)\n",
    "print ('Number of 0 values initially: %d'%sum(miss_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be48f8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0 values now: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-7ccaca10c74e>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"item_visibility\"][data['item_visibility'] == 0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "data[\"item_visibility\"][data['item_visibility'] == 0] = np.nan\n",
    "miss_bool = (data['item_visibility'] == 0)\n",
    "print ('Number of 0 values now: %d'%sum(miss_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deddedd",
   "metadata": {},
   "source": [
    "### Create a broad category of Type of Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b2f4c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food              10201\n",
       "Non-Consumable     2686\n",
       "Drinks             1317\n",
       "Name: item_type_combined, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Item type combine:\n",
    "data['item_identifier'].value_counts()\n",
    "data['item_type_combined'] = data['item_identifier'].apply(lambda x: x[0:2])\n",
    "data['item_type_combined'] = data['item_type_combined'].map({'FD':'Food',\n",
    "                                                             'NC':'Non-Consumable',\n",
    "                                                             'DR':'Drinks'})\n",
    "data['item_type_combined'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb24ff3",
   "metadata": {},
   "source": [
    "### Determine the years of operation of a store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738c9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "#Years:\n",
    "data['outlet_years'] = date.today().year - data['outlet_establishment_year']\n",
    "data['outlet_years'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a779b",
   "metadata": {},
   "source": [
    "### Modify categories of Item_Fat_Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607656d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Change categories of low fat:\n",
    "print ('Original Categories:')\n",
    "print (data['item_fat_content'].value_counts())\n",
    "\n",
    "print ('\\nModified Categories:')\n",
    "data['item_fat_content'] = data['item_fat_content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print (data['Item_Fat_Content'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mark non-consumables as separate category in low_fat:\n",
    "data.loc[data['item_type_combined']==\"Non-Consumable\",'item_fat_content'] = \"Non-Edible\"\n",
    "data['item_fat_content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8672c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fc27db",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f983d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding to impute missing values For regression, SVC, etc.\n",
    "le = LabelEncoder()\n",
    "#encoders=dict()\n",
    "series = data['outlet_size']\n",
    "data['outlet_size'] = pd.Series(le.fit_transform(series[series.notnull()]), index=series[series.notnull()].index)\n",
    "#encoders['Outlet_Size'] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the mean sales by type:\n",
    "data.pivot_table(values='Item_Outlet_Sales',index='Outlet_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0964e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'outlet_establishment_year': float,\n",
    "                'outlet_years': float}\n",
    "data = data.astype(convert_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29851d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Knn imputer to impute missing values instead of using mean, mode, median, etc.\n",
    "imputer = KNNImputer()\n",
    "data.loc[:,(data.dtypes=='float64').values] = imputer.fit_transform(data.loc[:,(data.dtypes=='float64').values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rounding off the imputed values\n",
    "data['outlet_size'] = np.round(data['outlet_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse transforming the encoded values\n",
    "data['Outlet_Size'] = le.inverse_transform(data['Outlet_Size'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba04d7",
   "metadata": {},
   "source": [
    "### Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e78ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the columns which have been converted to different types:\n",
    "data.drop(['item_Type','outlet_establishment_year'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729973",
   "metadata": {},
   "source": [
    "### Creating Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c3522",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = data.loc[:, data.columns != 'item_outlet_sales'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview.loc[[\"min\", \"max\"]].to_json(\"schema_in.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a5c0b1",
   "metadata": {},
   "source": [
    "### Dummy Variables Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20edd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['item_fat_content','outlet_location_type','outlet_size','outlet_type',\n",
    "                              'item_type_combined'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a7793",
   "metadata": {},
   "source": [
    "### Checking for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dbf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating VIF score for treating multicollinearity\n",
    "def vif_score(x):\n",
    "    temp =x\n",
    "    scaler = StandardScaler()\n",
    "    arr = scaler.fit_transform(temp)\n",
    "    return pd.DataFrame([[temp.columns[i], variance_inflation_factor(arr,i)] for i in range(arr.shape[1])], columns=[\"FEATURE\", \"VIF_SCORE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9307e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_score(data.loc[:,(data.dtypes=='float64').values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fa735",
   "metadata": {},
   "source": [
    "### Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6707b37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Divide into test and train:\n",
    "train = data.loc[data['source']==\"train\"]\n",
    "test = data.loc[data['source']==\"test\"]\n",
    "\n",
    "#Drop unnecessary columns:\n",
    "test.drop(['item_outlet_sales','source'],axis=1,inplace=True)\n",
    "train.drop(['source'],axis=1,inplace=True)\n",
    "\n",
    "#Export files as modified versions:\n",
    "#train.to_csv(\"train_modified.csv\",index=False)\n",
    "#test.to_csv(\"test_modified.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1565f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Identifier'].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bcd90f",
   "metadata": {},
   "source": [
    "# Function to model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735bfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c26cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target and ID columns:\n",
    "target = 'item_outlet_sales'\n",
    "IDcol = ['item_identifier','outlet_identifier']\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def modelfit(alg, dtrain, dtest, predictors, target, IDcol):\n",
    "        \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain[target])\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "\n",
    "    #Perform cross-validation:\n",
    "    cv_score = cross_val_score(alg, dtrain[predictors], dtrain[target], cv=20, scoring='neg_mean_squared_error')\n",
    "    cv_score = np.sqrt(np.abs(cv_score))\n",
    "    \n",
    "    #Print model report:\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"RMSE : %.4g\" % np.sqrt(metrics.mean_squared_error(dtrain[target].values, dtrain_predictions)))\n",
    "    print (\"CV Score : Mean - %.4g | Std - %.4g | Min - %.4g | Max - %.4g\" % (np.mean(cv_score),np.std(cv_score),np.min(cv_score),np.max(cv_score)))\n",
    "    \n",
    "    #Predict on testing data:\n",
    "    dtest[target] = alg.predict(dtest[predictors])\n",
    "    \n",
    "    #return model\n",
    "    #Export submission file:\n",
    "    #IDcol.append(target)\n",
    "    #submission = pd.DataFrame({ x: dtest[x] for x in IDcol})\n",
    "    #submission.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a273f8",
   "metadata": {},
   "source": [
    "### Normalizing data for certain algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "\n",
    "#Normalizing train data\n",
    "arr_train = scaler.fit_transform(train[predictors].values)\n",
    "train_scaled = pd.DataFrame(arr_train, index=train[predictors].index, columns=train[predictors].columns)\n",
    "train_scaled['item_identifier'] = train['item_identifier']\n",
    "train_scaled['outlet_identifier'] = train['outlet_identifier']\n",
    "train_scaled[target] = train[target]\n",
    "\n",
    "#Normalizing test data\n",
    "arr_test = scaler.fit_transform(test[predictors].values)\n",
    "test_scaled = pd.DataFrame(arr_test, index=test[predictors].index, columns=test[predictors].columns)\n",
    "test_scaled['item_identifier'] = test['item_identifier']\n",
    "test_scaled['outlet_identifier'] = test['outlet_identifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771c2ef9",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8812371",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465c10fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train_scaled.columns if x not in [target]+IDcol]\n",
    "\n",
    "# print predictors\n",
    "alg1 = LinearRegression()\n",
    "\n",
    "modelfit(alg1, train_scaled, test_scaled, predictors, target, IDcol)\n",
    "coef1 = pd.Series(alg1.coef_, predictors).sort_values()\n",
    "coef1.plot(kind='bar', title='Model Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad65a9",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e0442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train_scaled.columns if x not in [target]+IDcol]\n",
    "alg2 = Ridge(alpha=0.05)\n",
    "modelfit(alg2, train_scaled, test_scaled, predictors, target, IDcol)\n",
    "coef2 = pd.Series(alg2.coef_, predictors).sort_values()\n",
    "coef2.plot(kind='bar', title='Model Coefficients')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5dc747",
   "metadata": {},
   "source": [
    "### Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d331f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg3 = DecisionTreeRegressor(max_depth=15, min_samples_leaf=100)\n",
    "modelfit(alg3, train, test, predictors, target, IDcol)\n",
    "coef3 = pd.Series(alg3.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef3.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b02a89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = ['Item_MRP','Outlet_Type_Grocery Store','Outlet_Type_Supermarket Type3','Outlet_Years']\n",
    "alg4 = DecisionTreeRegressor(max_depth=8, min_samples_leaf=150)\n",
    "modelfit(alg4, train, test, predictors, target, IDcol)\n",
    "coef4 = pd.Series(alg4.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef4.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0550cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c90284",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af89e91",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc92b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg5 = RandomForestRegressor(n_estimators=200,max_depth=5, min_samples_leaf=100,n_jobs=4)\n",
    "modelfit(alg5, train, test, predictors, target, IDcol)\n",
    "coef5 = pd.Series(alg5.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef5.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd05bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [x for x in train.columns if x not in [target]+IDcol]\n",
    "alg6 = RandomForestRegressor(n_estimators=400,max_depth=6, min_samples_leaf=100,n_jobs=4)\n",
    "modelfit(alg6, train, test, predictors, target, IDcol)\n",
    "coef6 = pd.Series(alg6.feature_importances_, predictors).sort_values(ascending=False)\n",
    "coef6.plot(kind='bar', title='Feature Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(alg3, open(r'C:\\Users\\Manu\\Documents\\ineuron\\Internship\\Store_Sales_Prediction\\prediction_service\\model\\model.joblib' , 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "673770b192ebde9b8283f550af043a0bc4e381b5181944096fa066cfc91be5a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
